{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "76f4a708",
      "metadata": {
        "id": "76f4a708"
      },
      "source": [
        "🌱 인프런 📚 모두의 한국어 텍스트 분석과 자연어처리 with 파이썬 🐍 https://inf.run/FX4TP\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/corazzon/python-text-analysis/blob/main/0104-morpheme-konlpy-okt-output.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "## 형태소 분석\n",
        "\n",
        "\n",
        "* 한국어 형태소 분석은 한국어 텍스트를 가장 작은 의미 단위인 형태소로 분해하는 과정입니다. 한국어는 교착어의 특성을 가지고 있어, 하나의 단어가 여러 형태소로 구성되는 경우가 많습니다.\n",
        "    * 교착어 : https://ko.wikipedia.org/wiki/%EA%B5%90%EC%B0%A9%EC%96%B4\n",
        "    * 교착어는 고립어와 굴절어의 중간적 성격을 띠는 것으로 어근과 접사에 의해 단어의 기능이 결정되는 언어의 형태이다. '교착'은 아교와 같이 단단히 달라붙음을 뜻한다.\n",
        "    \n",
        "* 형태소 분석의 핵심 요소:\n",
        "    * 형태소(Morpheme): 의미를 가진 가장 작은 언어 단위. 한국어에서는 '가다', '학교', '좋아'와 같이 독립적으로 사용될 수 있는 단어 또는 어미, 접사 등이 이에 해당합니다.\n",
        "    * 어절(Token): 띄어쓰기로 구분된 각각의 단어. 하나의 어절은 여러 형태소로 구성될 수 있습니다.\n",
        "\n",
        "* 형태소 분석의 과정:\n",
        "    * 분해: 한국어 문장을 어절 단위로 분해합니다.\n",
        "    * 형태소 분석: 각 어절을 다시 형태소로 세분화합니다. 이 과정에서 어근, 접미사, 접두사, 조사 등이 구분됩니다.\n",
        "    * 품사 태깅(POS Tagging): 분리된 형태소에 품사 정보를 부여합니다. 예를 들어 명사, 동사, 형용사 등의 품사를 식별합니다.\n",
        "* 형태소 분석의 중요성:\n",
        "    * 정확한 의미 파악: 한국어는 하나의 어절이 복잡한 의미를 내포할 수 있어, 형태소 분석을 통해 정확한 의미를 파악할 수 있습니다.\n",
        "    * 자연어 처리의 기초: 형태소 분석은 텍스트 마이닝, 감성 분석, 기계 번역 등 다양한 NLP 작업의 기초가 됩니다.\n",
        "    * 문맥 이해: 한국어의 높임말, 어미 변화 등의 문맥적 요소를 이해하는 데 필수적입니다.\n",
        "    \n",
        "\n",
        "## KoNLPy 개요\n",
        "\n",
        "* KoNLPy (코엔엘파이):\n",
        "    * [KoNLPy: 파이썬 한국어 NLP — KoNLPy documentation](https://konlpy.org/ko/latest/)\n",
        "    * [형태소 분석 및 품사 태깅 — KoNLPy 0.4.3 documentation](https://konlpy-ko.readthedocs.io/ko/v0.4.3/morph/)\n",
        "    * 파이썬 기반의 라이브러리로, 한국어 텍스트의 형태소 분석, 품사 태깅 등을 제공합니다.\n",
        "    * 여러 한국어 형태소 분석 엔진을 통합하여 사용할 수 있으며, 대표적으로 Okt(Open Korean Text), Mecab, Komoran, Hannanum, Kkma 등이 있습니다.\n",
        "\n",
        "    * Okt (Open Korean Text, 이전의 Twitter 형태소 분석기):\n",
        "        * 속도가 빠르고 사용하기 쉬운 특징을 가지고 있습니다.\n",
        "        * 일상적인 언어, 특히 소셜 미디어 텍스트 분석에 적합합니다.\n",
        "    * Mecab:\n",
        "        * 은전한닢으로도 불리우며 일본어 형태소 분석기를 기반으로 한국어를 처리하기 위해 수정된 버전입니다.\n",
        "        * 설치가 까다롭기 때문에 파이썬으로 만들어진 Pecab을 사용하는 것을 추천합니다.\n",
        "    * Komoran:\n",
        "        * 정확도가 높으며, 특히 잘못된 맞춤법이나 띄어쓰기가 있는 텍스트에 강점을 보입니다.\n",
        "    * Hannanum:\n",
        "        * KAIST에서 개발한 분석기로, 학술적인 목적으로 사용되곤 합니다.\n",
        "    * Kkma (꼬꼬마):\n",
        "        * [꼬꼬마 세종 말뭉치 활용 시스템](http://kkma.snu.ac.kr/)\n",
        "        * 상세한 형태소 분석과 품사 태깅 기능을 제공합니다.\n",
        "\n",
        "## KoNLPy 외\n",
        "\n",
        "* Pecab\n",
        "    * [Pecab: Pure python Korean morpheme analyzer based on Mecab (https://github.com/hyunwoongko/pecab)\n",
        "* Soynlp\n",
        "    * https://github.com/lovit/soynlp\n",
        "\n",
        "## KoNLPy 설치\n",
        "\n",
        "```sh\n",
        "pip install --upgrade pip\n",
        "pip install JPype1\n",
        "pip install konlpy --upgrade\n",
        "```\n",
        "\n",
        "다음의 항목을 만족해야 konlpy를 윈도우나 맥에서 사용할 수 있습니다.\n",
        "대부분의 오류는 환경변수나 최신버전의 JDK가 설치되지 않아서 입니다. 공식문서에서는 1.7 이상의 JDK 를 권장하고 있습니다.\n",
        "\n",
        "```\n",
        "1) 최신 버전의 JAVA(JDK)를 설치\n",
        "2) JAVA_HOME 환경변수를 추가\n",
        "3) path 환경변수에 %JAVA_HOME%\\bin; 추가\n",
        "```\n",
        "\n",
        "설치 관련 자세한 내용은 다음을 참고해 보세요.\n",
        "\n",
        "https://konlpy.org/ko/latest/install/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "877864fc",
      "metadata": {
        "id": "877864fc"
      },
      "outputs": [],
      "source": [
        "# konlpy 가 설치되어 있지 않다면 설치합니다.\n",
        "# konlpy 는 다른 프로그래밍 언어(JAVA, C++)로 만들어진 형태소 분석기를 파이썬 인터페이스로 사용할 수 있는 도구 입니다.\n",
        "# JPype1도 파이썬에서 자바를 사용할 수 있도록 하는 도구입니다.\n",
        "# 인터페이스가 파이썬이지만 내부는 해당 언어로 동작하여 다른 언어도 함께 설치되어 있어야 합니다.\n",
        "# 그래서 설치는 꼭 공식문서를 참고해서 합니다.\n",
        "# Google Colab 에서는 아래 pip 구문 만으로 설치할 수 있으나 다른 운영체제 사용시 설치 문서를 참고해 주세요!\n",
        "# !pip install konlpy --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install konlpy --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxk1MyCiE7Mw",
        "outputId": "a69191e1-b822-4857-f258-2ceea894884e"
      },
      "id": "qxk1MyCiE7Mw",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.12/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from JPype1>=0.7.0->konlpy) (25.0)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (495 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.9/495.9 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.6.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "82a66596",
      "metadata": {
        "id": "82a66596"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #판다스 불러옵니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9aa26f25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9aa26f25",
        "outputId": "c20c23b8-e72e-4725-d920-311d50cadf19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'버스의 운행시간을 문의합니다. 어?!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "small_text = \"버스의 운행시간을 문의합니다. 어?!\"\n",
        "small_text\n",
        "#small_text라는 변수에 문장을 넣고 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "33ae38dd",
      "metadata": {
        "id": "33ae38dd"
      },
      "outputs": [],
      "source": [
        "# Kkma\n",
        "from konlpy.tag import Kkma\n",
        "kkma = Kkma()\n",
        "#Kkma(꼬꼬마): 상세한 형태소 분석과 품사 태깅 기능을 제공"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e86e46a",
      "metadata": {
        "id": "9e86e46a",
        "outputId": "3ea5f5dc-ecb9-4c35-ed78-0c00a4109e14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['버스', '운행', '운행시간', '시간', '문의']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kkma.nouns(small_text) #small_text에 저장된 문장의 명사만 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b5b2d29",
      "metadata": {
        "id": "7b5b2d29",
        "outputId": "db217b70-42aa-4a94-810d-a1947bcd5bb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('버스', 'NNG'),\n",
              " ('의', 'JKG'),\n",
              " ('운행', 'NNG'),\n",
              " ('시간', 'NNG'),\n",
              " ('을', 'JKO'),\n",
              " ('문의', 'NNG'),\n",
              " ('하', 'VV'),\n",
              " ('ㅂ니다', 'EFN'),\n",
              " ('.', 'SF'),\n",
              " ('어', 'VV'),\n",
              " ('어', 'ECS'),\n",
              " ('?', 'SF'),\n",
              " ('!', 'SF')]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kkma.pos(small_text)\n",
        "#small_text에 저장된 문장의 각 품사를 태깅해줌 NNG 일반명사"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iUHi8I-3HVPF"
      },
      "id": "iUHi8I-3HVPF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gT0hJA51HhMj"
      },
      "id": "gT0hJA51HhMj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a88b72b",
      "metadata": {
        "id": "0a88b72b",
        "outputId": "95dfc0ef-2666-4c63-c341-ad447935662b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'마침표, 물음표, 느낌표'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kkma.tagset[\"SF\"]\n",
        "#SF가 어떤 걸 의미하는지 알려줌(위에서 마침표, 물음표, 느낌표순으로 나와있음. 그럼 kkma.tagset[\"NNG\"]를 치면... '일반명사' 이렇게 나올 듯)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90ece976",
      "metadata": {
        "id": "90ece976",
        "outputId": "52563609-bcfa-4135-a5e3-1b23ad975e78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "버스  :  보통명사\n",
            "운행  :  보통명사\n",
            "시간  :  보통명사\n",
            "문의  :  보통명사\n"
          ]
        }
      ],
      "source": [
        "kkma_tagset = kkma.tagset\n",
        "\n",
        "for txt, pos in kkma.pos(small_text):\n",
        "    if pos.startswith(\"N\"): # 사용자가 지정하는 특정 문자로 시작하는지 확인(여기에서는 N 즉 명사를 의미함)\n",
        "        print(txt, \" : \", kkma_tagset[pos]) #small_text에 저장된 문장에서, 명사가 있다면 그 단어 : 품사 이름"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2c5c533",
      "metadata": {
        "id": "c2c5c533"
      },
      "source": [
        "### 어간 추출(語幹 抽出, 영어: stemming)\n",
        "\n",
        "형태론 및 정보 검색 분야에서 어형이 변형된 단어로부터 접사 등을 제거하고 그 단어의 어간을 분리해 내는 것을 의미한다. 여기서 어간은 반드시 어근과 같아야 할 필요는 없으며, 어근과 차이가 있더라도 관련이 있는 단어들이 일정하게 동일한 어간으로 맵핑되게 하는 것이 어간 추출의 목적이다. 1960년대부터 컴퓨터 과학 분야에서 다양한 어간 추출 관련 알고리즘들이 연구되어 왔다. 많은 웹 검색 엔진들은 동일한 어간을 가진 단어들을 동의어로 취급하는 방식으로 질의어 확장을 하여 검색 결과의 품질을 높인다.\n",
        "\n",
        "어간 추출 프로그램은 흔히 스테밍 알고리즘(stemming algorithm) 또는 스테머(stemmer)라 불린다.\n",
        "\n",
        "* [어간 추출 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%EC%96%B4%EA%B0%84_%EC%B6%94%EC%B6%9C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "42c5b75f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42c5b75f",
        "outputId": "a4984ef5-abf8-491b-cfa5-65fd2b62f4f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('버스', 'Noun'),\n",
              " ('운행', 'Noun'),\n",
              " ('시간', 'Noun'),\n",
              " ('을', 'Josa'),\n",
              " ('문의', 'Noun'),\n",
              " ('하다', 'Verb'),\n",
              " ('.', 'Punctuation'),\n",
              " ('어', 'Eomi'),\n",
              " ('?!', 'Punctuation'),\n",
              " ('ㅋㅋㅋ', 'KoreanParticle'),\n",
              " ('~~~', 'Punctuation')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Okt\n",
        "# steming 기능을 제공\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "okt = Okt()\n",
        "# okt.tagset\n",
        "okt.pos(\"버스 운행시간을 문의합니다. 어?! ㅋㅋㅋㅋㅋ ~~~\", norm=True, stem=True)\n",
        "#해당 문장 형태소로 나눈 뒤, 형태소와 품사 정보를 저장하고 정리한 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c91b2f0",
      "metadata": {
        "id": "2c91b2f0",
        "outputId": "c21270f7-add8-4e16-a954-8a3846d9477e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('버스', 'Noun'),\n",
              " ('운행', 'Noun'),\n",
              " ('시간', 'Noun'),\n",
              " ('을', 'Josa'),\n",
              " ('문의', 'Noun'),\n",
              " ('하다', 'Verb'),\n",
              " ('.', 'Punctuation'),\n",
              " ('어', 'Eomi'),\n",
              " ('?!', 'Punctuation')]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "okt.pos(\"버스 운행시간을 문의했었습니다. 어?!\", stem=True)\n",
        "#시제가 중요하면 stem을 안 씀. 위 설명과 마찬가지 stem을 트루로 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8ca0e231",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ca0e231",
        "outputId": "a7ad6aa6-6555-43b5-fe64-08eee166f864"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('버스', 'Noun'),\n",
              " ('운행', 'Noun'),\n",
              " ('시간', 'Noun'),\n",
              " ('을', 'Josa'),\n",
              " ('문의', 'Noun'),\n",
              " ('하다', 'Verb'),\n",
              " ('.', 'Punctuation'),\n",
              " ('어', 'Eomi'),\n",
              " ('?!', 'Punctuation')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "okt.pos(\"버스 운행시간을 문의했다. 어?!\", stem=True)\n",
        "#위와 마찬가지로 했다 -> '하다' 원형으로 나옴"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d1209f9",
      "metadata": {
        "id": "0d1209f9"
      },
      "outputs": [],
      "source": [
        "# 형태소 분석기(Okt) 불러오기\n",
        "# ['Josa', 'Eomi', 'Punctuation'] 조사, 어미, 구두점 제거\n",
        "\n",
        "def okt_clean(text):\n",
        "    clean_text = []\n",
        "    okt_pos = okt.pos(text, stem=True)\n",
        "    for txt, pos in okt_pos:\n",
        "        if pos not in ['Josa', 'Eomi', 'Punctuation']:\n",
        "            clean_text.append(txt)\n",
        "            #조사, 어미, 구두점이 문장에 없다면 clean_text라는 배열에 추가\n",
        "    return \" \".join(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6803b67",
      "metadata": {
        "id": "f6803b67",
        "outputId": "46a33eab-3e55-4067-cdc8-432056f5780b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'지하철 이용 시간 문의 하다 네'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "okt_clean(text=\"지하철 이용시간 문의했었습니다. 네?!\")\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "625b2735",
      "metadata": {
        "id": "625b2735",
        "outputId": "171fedf0-a105-493f-c8db-963a5a945a2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'버스 운행 시간 문의 하다'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "okt_pos = okt.pos(\"버스 운행시간을 문의했다. 어?!\", stem=True)\n",
        "clean_text = []\n",
        "for txt, pos in okt_pos:\n",
        "    if pos not in ['Josa', 'Eomi', 'Punctuation']:\n",
        "        clean_text.append(txt)\n",
        "\" \".join(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c714d794",
      "metadata": {
        "id": "c714d794"
      },
      "source": [
        "## 여러 문서에 적용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c149ba5",
      "metadata": {
        "id": "4c149ba5",
        "outputId": "66f9a6a9-b5e9-4b4c-9474-f1e357f2440f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(45678, 7)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# read_json 으로 url 데이터 불러오기\n",
        "url = \"https://raw.githubusercontent.com/KLUE-benchmark/KLUE/main/klue_benchmark/ynat-v1.1/ynat-v1.1_train.json\"\n",
        "df = pd.read_json(url)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48950951",
      "metadata": {
        "id": "48950951",
        "outputId": "c1a2bb83-2f1c-4f88-c321-81560c2df525"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:10<00:00, 912.41it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "title_head = df[\"title\"].head(10000)\n",
        "title_clean = title_head.progress_map(okt_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25d7de5c",
      "metadata": {
        "id": "25d7de5c",
        "outputId": "602b51d9-be02-4c73-a5b4-721b7bb40af9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0            유튜브 내달 2일까지 크리에이터 지원 공간 운영\n",
              "1               어버이날 맑다가 흐려져…남부지방 옅은 황사\n",
              "2           내년부터 국가RD 평가 때 논문건수는 반영 않는다\n",
              "3       김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것\n",
              "4        회색인간 작가 김동식 양심고백 등 새 소설집 2권 출간\n",
              "                     ...               \n",
              "9995        게시판 KB손보 소규모 공연장 안전시설 설치 지원\n",
              "9996                      신간 소피아 로렌의 시간\n",
              "9997     창비 세월호 책 다시 봄이 올 거예요 전자책 무료 배포\n",
              "9998              탬파베이 최지만 시즌 1호 솔로포 폭발\n",
              "9999         NHN엔터 3분기 영업이익 23억원…흑자전환종합\n",
              "Name: title, Length: 10000, dtype: object"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "title_head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ff6901",
      "metadata": {
        "id": "a9ff6901",
        "outputId": "f199c1d9-f349-4f0b-92df-864f28a08ef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                 유튜브 내달 2일 까지 크리에이터 지원 공간 운영\n",
              "1                    어버이날 맑다 흐려지다 남부 지방 옅다 황사\n",
              "2                   내년 국가 RD 평가 때 논문 건수 반영 않다\n",
              "3             김명자 신임 과총 회장 원로 젊다 과학자 지혜 모으다 것\n",
              "4       회색 인간 작가 김 동식 양심 고백 등 새 소설 집 2 권 추다 간\n",
              "                        ...                  \n",
              "9995            게시판 KB 손보 소규모 공연장 안전 시설 설치 지원\n",
              "9996                             신간 소피아 로렌 시간\n",
              "9997             창비 세월호 책 다시 봄 오다 거 전자책 무료 배포\n",
              "9998                    탬파베이 최 시즌 1 호 솔로 포 폭발\n",
              "9999          NHN 엔터 3분 기 영업 이익 23억원 흑자 전환 종합\n",
              "Name: title, Length: 10000, dtype: object"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "title_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19241043",
      "metadata": {
        "id": "19241043"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e295622",
      "metadata": {
        "id": "2e295622"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcd8c511",
      "metadata": {
        "id": "bcd8c511"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d364b5ea",
      "metadata": {
        "id": "d364b5ea"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdbe3b6b",
      "metadata": {
        "id": "cdbe3b6b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d3d8ea5",
      "metadata": {
        "id": "8d3d8ea5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": false,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": false,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}